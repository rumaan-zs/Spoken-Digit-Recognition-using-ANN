{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoken Digit Recognition (0-9) using Hidden Markov Models (HMMs)\n",
    "The world has been moving fast towards a more interactive and hands-off interface for everyday tasks\n",
    "and voice plays a major role in it. Voice activated or voice controlled devices, software and also AI\n",
    "assistants are on the rise. The goal of this project is to develop an effective system to detect and classify\n",
    "spoken digits (0-9) using Hidden Markov Models (HMMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary files and extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Audio Preprocessing\n",
    "import librosa\n",
    "import librosa.display as dsp\n",
    "from IPython.display import Audio\n",
    "\n",
    "# For Data Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For data viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "librosa.load(file): This function is part of the Librosa library, which is commonly used for audio and music signal processing in Python. It loads the audio file specified by the file variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(digit=0):\n",
    "    # Generate a random integer for 'sample' between 1 (inclusive) and 50 (inclusive)\n",
    "    sample = np.random.randint(0, 49)\n",
    "  \n",
    "    possible_names = ['yweweler' , 'theo' , 'nicolas' , 'lucas' , 'jackson' , 'george']\n",
    "    random_name = np.random.choice(possible_names)\n",
    "    \n",
    "    # sample is the digit speaker_identifier is the speaker identifier and index is the identifier\n",
    "    file = f\"EnterDatasetlocationhere/{digit}_{random_name}_{sample}.wav\"\n",
    "    \n",
    "    data,sample_rate = librosa.load(file)\n",
    "    \n",
    "    # Plot the audio wave\n",
    "    dsp.waveshow(data,sr=sample_rate)\n",
    "    plt.show()\n",
    "    \n",
    "    # Show the widget\n",
    "    return Audio(data=data,rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the plots of the various digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 0\n",
    "get_audio(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 1\n",
    "get_audio(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 2\n",
    "get_audio(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 3\n",
    "get_audio(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 4\n",
    "get_audio(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 5\n",
    "get_audio(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 6\n",
    "get_audio(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 7\n",
    "get_audio(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 8\n",
    "get_audio(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the audio and plot of digit 9\n",
    "get_audio(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function which return audio file for a mentioned digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_audio_raw(digit=0):\n",
    "    # Generate a random integer for 'sample' between 1 (inclusive) and 50 (inclusive)\n",
    "    sample = np.random.randint(0, 49)\n",
    "  \n",
    "    possible_names = ['yweweler' , 'theo' , 'nicolas' , 'lucas' , 'jackson' , 'george']\n",
    "    random_name = np.random.choice(possible_names)\n",
    "    \n",
    "    # sample is the digit speaker_identifier is the speaker identifier and index is the identifier\n",
    "    file = f\"datasetLocationHere/{digit}_{random_name}_{sample}.wav\"\n",
    "    \n",
    "    \n",
    "    # Get Audio from the location\n",
    "    data,sample_rate = librosa.load(file)\n",
    "\n",
    "    # Return audio\n",
    "    return data,sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the spectograms of the various digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectogram_of(digit):\n",
    "    # Read the audio file\n",
    "    data,sr = get_audio_raw(digit)\n",
    "    # Apply Short-Time-Fourier-Transformer to transform data\n",
    "    D = librosa.stft(data)\n",
    "    # Converting frequency to decible\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D),ref=np.max)\n",
    "    # Plot the transformed data\n",
    "    librosa.display.specshow(S_db,x_axis='time',y_axis='log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the subplots to display the spectogram for various data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating subplots\n",
    "fig,ax = plt.subplots(5,2,figsize=(15,30))\n",
    "\n",
    "# Initializing row and column variables for subplots\n",
    "row = 0\n",
    "column = 0\n",
    "\n",
    "for digit in range(10):  \n",
    "    # Read the audio file\n",
    "    data,sr = get_audio_raw(digit)\n",
    "    # Apply Short-Time-Fourier-Transformer to transform data\n",
    "    D = librosa.stft(data)\n",
    "    # Converting frequency to decible\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D),ref=np.max)\n",
    "    # Plot the transformed data\n",
    "    ax[row,column].set_title(f\"Spectogram of digit {digit}\")\n",
    "    librosa.display.specshow(S_db,x_axis='time',y_axis='log',ax=ax[row,column])\n",
    "    \n",
    "    # Conditions for positioning of the plots\n",
    "    if column == 1:\n",
    "        column = 0\n",
    "        row += 1\n",
    "    else:\n",
    "        column+=1\n",
    "        \n",
    "    \n",
    "plt.tight_layout(pad=3)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs are a compact representation of the spectrum(When a waveform is represented by a summation of possibly infinite number of sinusoids) of an audio signal.\n",
    "MFCC coefficients contain information about the rate changes in the different spectrum bands.\n",
    "If a cepstral coefficient has a positive value, the majority of the spectral energy is concentrated in the low-frequency regions. On the other hand, if a cepstral coefficient has a negative value, it represents that most of the spectral energy is concentrated at high frequencies.\n",
    "\n",
    "will take a audio file as input and output extracted features using MEL_FREQUENCY CEPSTRAL COEFFICIENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file):\n",
    "    # Load audio and sample rate of audio\n",
    "    audio,sample_rate = librosa.load(file)\n",
    "    # Extract features using mel-frequency coefficient\n",
    "    extracted_features = librosa.feature.mfcc(y=audio,\n",
    "                                              sr=sample_rate,\n",
    "                                              n_mfcc=40)\n",
    "    \n",
    "    # Scale the extracted features\n",
    "    extracted_features = np.mean(extracted_features.T,axis=0)\n",
    "    # Return the extracted features\n",
    "    return extracted_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset using the extracted MFCC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_create_dataset():\n",
    "    # Path of folder where the audio files are present\n",
    "    root_folder_path = \"EnterPathOfFileWithAudioNotes/\"\n",
    "    \n",
    "    # Empty List to create dataset\n",
    "    dataset = []\n",
    "    \n",
    "    # Iterating through folders where each folder has audio of each digit\n",
    "    for digit in tqdm(range(10), colour='green'):\n",
    "        # Iterate through random names \n",
    "        for random_name in ['yweweler' , 'theo' , 'nicolas' , 'lucas' , 'jackson' , 'george']:  \n",
    "            # Iterate through samples\n",
    "            for sample in tqdm(range(0, 50), colour='blue'):\n",
    "                # Construct the file path\n",
    "                file_path = os.path.join(root_folder_path, f\"{digit}_{random_name}_{sample}.wav\")\n",
    "\n",
    "                # Pass path of file to extract_features() function to create features\n",
    "                extracted_features = extract_features(file_path)\n",
    "                \n",
    "                # Append a list where the feature represents a column and class of the digit represents another column\n",
    "                dataset.append([extracted_features, str(digit)])  # Assuming 'digit' is converted to a string for class label\n",
    "\n",
    "    # After iterating through all the folders, convert the list to a DataFrame\n",
    "    print(\"Extracted Features and Created Dataset Successfully !!\")\n",
    "    return pd.DataFrame(dataset, columns=['features', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset by calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocess_and_create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the frist 10 elements of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the frequency of each letter ion the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['class'] = [int(x) for x in dataset['class']]\n",
    "# Check the frequency of classes of audio\n",
    "dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that returns the extracted features without scaling (MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features_without_scaling(audio_data,sample_rate):\n",
    "#     # Extract features using mel-frequency coefficient\n",
    "#     extracted_features = librosa.feature.mfcc(y=audio_data,\n",
    "#                                               sr=sample_rate,\n",
    "#                                               n_mfcc=40)\n",
    "    \n",
    "    # # Return Without Scaling\n",
    "    # return extracted_features\n",
    "\n",
    "def extract_features_without_scaling(audio_data, sample_rate):\n",
    "    # Extract features using mel-frequency coefficient\n",
    "    extracted_features = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40, n_fft=2048, hop_length=512)\n",
    "\n",
    "    # Return without reshaping\n",
    "    return extracted_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating subplots for the MFCC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating subplots\n",
    "fig,ax = plt.subplots(5,2,figsize=(15,30))\n",
    "\n",
    "# Initializing row and column variables for subplots\n",
    "row = 0\n",
    "column = 0\n",
    "\n",
    "for digit in range(10):  \n",
    "    # Get Audio of different class(0-9)\n",
    "    audio_data,sample_rate = get_audio_raw(digit)\n",
    "    \n",
    "    # Extract Its MFCC\n",
    "    mfcc = extract_features_without_scaling(audio_data,sample_rate)\n",
    "    print(f\"Shape of MFCC of audio digit {digit} ---> \",mfcc.shape)\n",
    "    \n",
    "    # Display the plots and its title\n",
    "    ax[row,column].set_title(f\"MFCC of audio class {digit} across time\")\n",
    "    librosa.display.specshow(mfcc,sr=22050,ax=ax[row,column])\n",
    "    \n",
    "    # Set X-labels and y-labels\n",
    "    ax[row,column].set_xlabel(\"Time\")\n",
    "    ax[row,column].set_ylabel(\"MFCC Coefficients\")\n",
    "    \n",
    "    # Conditions for positioning of the plots\n",
    "    if column == 1:\n",
    "        column = 0\n",
    "        row += 1\n",
    "    else:\n",
    "        column+=1\n",
    "        \n",
    "    \n",
    "plt.tight_layout(pad=3)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train test split on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Seperate the audio and its class as X and Y\n",
    "X = np.array(dataset['features'].to_list())\n",
    "Y = np.array(dataset['class'].to_list())\n",
    "# Create train set and test set\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,train_size=0.75,shuffle=True,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chekcing the shape of the data\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create an ANN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# To create a checkpoint and save the best model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# To load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# To check the metrics of the model\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crete a Sequential Object\n",
    "model = Sequential()\n",
    "# Add first layer with 100 neurons to the sequental object\n",
    "model.add(Dense(100,input_shape=(40,),activation='relu'))\n",
    "# Add second layer with 200 neurons to the sequental object\n",
    "model.add(Dense(100,activation='relu'))\n",
    "# Add third later with 100 neurons to the sequental object\n",
    "model.add(Dense(100,activation='relu'))\n",
    "\n",
    "# Output layer With 10 neurons as it has 10 classes\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Checkpoint & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs for training\n",
    "num_epochs = 100\n",
    "# Set the batch size for training\n",
    "batch_size = 32\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=num_epochs,batch_size=batch_size,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = [np.argmax(i) for i in Y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the metrics\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style as dark\n",
    "sns.set_style(\"dark\")\n",
    "# Set figure size\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "# Plot the title\n",
    "plt.title(\"CONFUSION MATRIX FOR MNIST AUDIO PREDICTION\")\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix([int(x) for x in Y_test],Y_pred)\n",
    "# Plot confusion matrix as heatmap\n",
    "sns.heatmap(cm, annot=True, cmap=\"PuRd\", fmt='g', cbar=False)\n",
    "# Set x-label and y-label\n",
    "plt.xlabel(\"ACTUAL VALUES\")\n",
    "plt.ylabel(\"PREDICTED VALUES\")\n",
    "\n",
    "# Plot the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have the functions get_audio_raw, extract_features, and model defined\n",
    "\n",
    "# Get a random digit (0-9)\n",
    "random_digit = np.random.randint(0, 10)\n",
    "\n",
    "# Get a random name from the list\n",
    "name_list = ['yweweler', 'theo', 'nicolas', 'lucas', 'jackson', 'george']\n",
    "random_name = random.choice(name_list)\n",
    "\n",
    "# Get a random sample index (1-50)\n",
    "random_sample = np.random.randint(0, 50)\n",
    "\n",
    "# Construct the file path\n",
    "file_path = os.path.join(\"EnterFilePath/\", f\"{random_digit}_{random_name}_{random_sample}.wav\")\n",
    "\n",
    "# Load an audio file corresponding to the random digit\n",
    "audio_data, sample_rate = get_audio_raw(random_digit)\n",
    "\n",
    "# Extract features from the loaded audio file\n",
    "extracted_features_rand = extract_features(file_path)\n",
    "\n",
    "# Reshape the features to match the input shape expected by the model\n",
    "reshaped_features = extracted_features_rand.reshape(1, -1)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "prediction = model.predict(reshaped_features)\n",
    "predicted_digit = np.argmax(prediction)\n",
    "\n",
    "# Display the original digit, predicted digit, and the audio wave\n",
    "print(f\"Original Digit: {random_digit}\")\n",
    "print(f\"Predicted Digit: {predicted_digit}\")\n",
    "\n",
    "# Plot the audio wave\n",
    "dsp.waveshow(audio_data, sr=sample_rate)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
